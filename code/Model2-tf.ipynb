{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from util import SimpleArrayIterator\n",
    "from datetime import datetime\n",
    "print('Imports done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickles...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Loading pickles...')\n",
    "train_question_1 = pickle.load(open('train_question_1.pkl', 'r'))\n",
    "train_question_2 = pickle.load(open('train_question_2.pkl', 'r'))\n",
    "train_labels = pickle.load(open('train_labels.pkl', 'r'))\n",
    "map_index_vec = pickle.load(open('map_index_vec.pkl', 'r'))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/'\n",
    "logdir = './logs_2'\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "dim = 50\n",
    "N = len(train_question_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_symbols = len(map_index_vec)\n",
    "embedding_weights = np.zeros((n_symbols, 50), dtype=np.float32)\n",
    "for index, vec in map_index_vec.items():\n",
    "    embedding_weights[index,:] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "with tf.name_scope(\"data\"):\n",
    "    q1 = tf.placeholder(tf.float32, shape=[batch_size, None], name='q1')\n",
    "    q2 = tf.placeholder(tf.float32, shape=[batch_size, None], name='q2')\n",
    "    target = tf.placeholder(tf.float32, shape=[batch_size], name='target')\n",
    "    print target\n",
    "\n",
    "with tf.variable_scope('embedding') as scope:\n",
    "    embed_q1 = tf.nn.embedding_lookup(embedding_weights, q1)\n",
    "    scope.reuse_variables()\n",
    "    embed_q2 = tf.nn.embedding_lookup(embedding_weights, q2)\n",
    "\n",
    "with tf.variable_scope('lstm') as scope:\n",
    "    reducemax_q1 = tf.reduce_max(conv1_q1, axis=[1,2])\n",
    "\n",
    "with tf.variable_scope('reducemax_q2') as scope:\n",
    "    reducemax_q2 = tf.reduce_max(conv1_q2, axis=[1,2])\n",
    "    print reducemax_q2\n",
    "\n",
    "with tf.variable_scope('lr') as scope:\n",
    "    w = tf.Variable(tf.truncated_normal([2*CONV_OPS,1], stddev=0.1), name='weights')\n",
    "    b = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "\n",
    "    x = tf.concat(values=[reducemax_q1,reducemax_q2],axis=1)\n",
    "    logits = tf.matmul(x, w) + b\n",
    "    logits = tf.reshape(logits, [-1])\n",
    "\n",
    "with tf.name_scope('lr') as scope:\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=target))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy,global_step=global_step)\n",
    "\n",
    "correct_prediction = tf.equal(tf.round(tf.sigmoid(logits)), target)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"summaries\"):\n",
    "    tf.summary.scalar(\"loss\", cross_entropy)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    tf.summary.histogram(\"histogram_loss\", cross_entropy)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    it = PaddedDataIterator(inputs)\n",
    "\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(os.path.dirname(checkpoint_path))\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print global_step.eval()\n",
    "\n",
    "    writer = tf.summary.FileWriter('./my_graph', sess.graph)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        batch = it.next_batch(batch_size)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print batch['vec1'].shape\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={q1: batch['vec1'],\n",
    "                target: batch['is_duplicate'],\n",
    "                q2: batch['vec2']})\n",
    "            print('Step %d: Training accuracy %g' % (i, train_accuracy))\n",
    "            print(\"{} Saving checkpoint of model...\".format(datetime.now()))\n",
    "\n",
    "            #save checkpoint of the model\n",
    "            checkpoint_name = os.path.join(checkpoint_path, 'model_step'+str(i)+'.ckpt')\n",
    "            save_path = saver.save(sess, checkpoint_name)\n",
    "\n",
    "            print(\"{} Model checkpoint saved at {}\".format(datetime.now(), checkpoint_name))\n",
    "\n",
    "        _,summary = sess.run([train_step,summary_op], feed_dict={q1: batch['vec1'], q2: batch['vec2'], target: batch['is_duplicate']})\n",
    "        writer.add_summary(summary, global_step = global_step.eval())\n",
    "\n",
    "    checkpoint_name = os.path.join(checkpoint_path, 'model_train.ckpt')\n",
    "    save_path = saver.save(sess, checkpoint_name)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
